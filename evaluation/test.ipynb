{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/ansaripo/miniconda3/envs/robots/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As streaming television services continue to gain market share, there are a number of reasons why Netflix might be in trouble. Time Warner is taking its HBO content online, Amazon offers premium content for a monthly fee, and Hulu has reached nine million users. While these competitors may cause a bit of worry, it’s not the end of the world. Although Netflix has a huge amount of potential, the increased competition is unlikely to hurt its profitability.\n",
      "While the global pandemic last year caused a major shakeup in Hollywood, Netflix should not rest on its laurels. With a variety of rivals on the rise, it’s unlikely that it can continue to rely on its current performance. Despite the competition, the company has made a number of impactful moves across the board, including clamping down on password sharing. And in the coming years, Netflix should continue to grow and compete with new competitors.\n",
      "With more competitors entering the streaming space, Netflix is likely to face a more difficult time keeping its current market share. Disney has been investing heavily in the service and Amazon is expected to do the same. Both companies expect to add 35-40 million subscribers per year through 2024. Despite the competition, Netflix still remains the top streaming service. Its lack of original content has hurt its numbers in the last few quarters. Its only big original hit in the US was Cobra Kai, which only got four seasons. \n",
      "Whether or not it gets a second season of The Witcher is another question.\n",
      "Whether or not it gets a second season of Stranger Things is another question.\n",
      "Whether or not it gets a fifth season of The Witcher is another question.\n",
      "Whether or not it gets a second season of Black Mirror is another question.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/news_factor.csv')\n",
    "\n",
    "print(data.loc[0, 'full_prefix'])\n",
    "print(data.loc[0, 'completion'])\n",
    "print(data.loc[0, 'contradiction_0'])\n",
    "print(data.loc[0, 'contradiction_1'])\n",
    "print(data.loc[0, 'contradiction_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/ansaripo/miniconda3/envs/robots/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# load data\n",
    "def extract_example(row):\n",
    "    return {'full_prefix': row.full_prefix, 'completion': row.completion,\n",
    "            'contradictions': [row.contradiction_0, row.contradiction_1, row.contradiction_2]}\n",
    "\n",
    "\n",
    "def read_data(path, prefix_col):\n",
    "    df = pd.read_csv(path)[[prefix_col, 'doc_id', 'completion', 'contradiction_0', 'contradiction_1', 'contradiction_2']]\n",
    "    df.rename(columns={prefix_col: 'full_prefix'}, inplace=True)\n",
    "    return df.apply(lambda row: extract_example(row), axis=1).to_list()\n",
    "\n",
    "# load model\n",
    "def load_tokenizer(model_name, max_tokens):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='right', truncation_side='left',\n",
    "                                              model_max_length=max_tokens)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def load_model_and_tokenizer(model_name, cache_dir=None, max_tokens=1024):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    multi_gpus = torch.cuda.device_count() > 1\n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    model_args = {}\n",
    "    if cache_dir is not None and device != 'cpu':\n",
    "        model_args[\"cache_dir\"] = cache_dir\n",
    "    if multi_gpus:\n",
    "        model_args[\"device_map\"] = \"auto\"\n",
    "        model_args[\"low_cpu_mem_usage\"] = True\n",
    "    if hasattr(config, \"torch_dtype\") and config.torch_dtype is not None:\n",
    "        model_args[\"torch_dtype\"] = config.torch_dtype\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, **model_args).eval()\n",
    "    if not multi_gpus:\n",
    "        model = model.to(device)\n",
    "    tokenizer = load_tokenizer(model_name, max_tokens)\n",
    "    print(model.dtype)\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "    return model, tokenizer, device\n",
    "\n",
    "# prepare examples for evaluation\n",
    "def format_data(ex):\n",
    "    prefix = ex['full_prefix']\n",
    "    completion = ex['completion']\n",
    "    contradictions = ex['contradictions']\n",
    "\n",
    "    # make sure completion don't contain trailing spaces\n",
    "    completion = completion.lstrip(' ')\n",
    "    contradictions = [cont.lstrip(' ') for cont in contradictions]\n",
    "\n",
    "    # if the prefix ends with a new line, just concatenate.\n",
    "    # Else, add space to the completion, remove it from the prefix if necessary\n",
    "    if prefix.endswith(' '):\n",
    "        prefix = prefix[:-1]\n",
    "        batch = [f\"{prefix} {completion}\"] + [f\"{prefix} {cont}\" for cont in contradictions]\n",
    "        labels_batch = [f\" {completion}\"] + [f\" {cont}\" for cont in contradictions]\n",
    "    else:\n",
    "        batch = [f\"{prefix}{completion}\"] + [f\"{prefix}{cont}\" for cont in contradictions]\n",
    "        labels_batch = [completion] + contradictions\n",
    "    return batch, labels_batch\n",
    "\n",
    "\n",
    "def prep_batch(ex, tokenizer, device):\n",
    "    # prepare examples for tokenization\n",
    "    batch, labels_batch = format_data(ex)\n",
    "    # encode full text (context + completions)\n",
    "    encoding = tokenizer(batch, padding=True, truncation=True, return_tensors='pt', add_special_tokens=False).to(device)\n",
    "    encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "    input_ids = encoding['input_ids']\n",
    "    # extract labels from input text\n",
    "    labels_encoding = tokenizer(labels_batch, padding=True, truncation=True, return_tensors='pt', add_special_tokens=False).to(device)\n",
    "    input_lens = torch.sum(encoding['attention_mask'], axis=-1).to(device)\n",
    "    target_lens = torch.sum(labels_encoding['attention_mask'], axis=-1).to(device)\n",
    "    offsets = input_lens - target_lens\n",
    "    positions = torch.arange(0, encoding['input_ids'].size(-1))[None, :].to(device)\n",
    "    labels_mask = (positions >= offsets[:, None]) * encoding['attention_mask']\n",
    "\n",
    "    labels = input_ids*labels_mask + (-100)*(1-labels_mask)\n",
    "\n",
    "    # assert all labels match\n",
    "    for input_id, label, target_len, offset, comp in zip(input_ids, labels, target_lens, offsets, labels_batch):\n",
    "        assert torch.all(input_id[offset: offset + target_len].eq(label[offset:offset+target_len])), \"labels don't appear in input ids\"\n",
    "        assert torch.all(label[:offset] == -100), \"labels include redundant prefix\"\n",
    "        assert torch.all(label[offset + target_len:] == -100), \"labels include redundant suffix\"\n",
    "    encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "    return encoding, labels, target_lens\n",
    "\n",
    "\n",
    "def get_losses(logits, labels):\n",
    "    loss_fct = CrossEntropyLoss(reduction=\"none\")\n",
    "    nll = loss_fct(logits.reshape(-1, logits.size(-1)), labels.reshape(-1)).cpu()\n",
    "    nll = nll.view(labels.size())\n",
    "    return nll\n",
    "\n",
    "\n",
    "def run_eval(model, tokenizer, data, device):\n",
    "    all_scores = torch.empty((len(data), 4))\n",
    "    for i, ex in tqdm(enumerate(data)):\n",
    "        print(ex)\n",
    "        break\n",
    "        input_ids, target, target_lens = prep_batch(ex, tokenizer, device=device)\n",
    "        with torch.no_grad():\n",
    "            out = model(**input_ids)\n",
    "            nll = get_losses(out.logits[..., :-1, :], target[:, 1:])\n",
    "\n",
    "        # get scores for the full the sequence\n",
    "        scores = torch.sum(nll, axis=-1)\n",
    "        scores = scores / target_lens.to('cpu')\n",
    "        all_scores[i] = scores\n",
    "        if i % 100 == 0:\n",
    "            acc = np.sum(np.argmin(np.array(all_scores[:(i+1), :].tolist()), axis=1) == 0) / (i+1)\n",
    "            print(f\"processed: {i+1}/{len(data)} examples. accuracy: {acc}\")\n",
    "    return all_scores\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    prefix_col = 'turncated_prefixes'\n",
    "    data = read_data(args.data_file, prefix_col)\n",
    "    model, tokenizer, device = load_model_and_tokenizer(args.model_name, args.cache_dir, max_tokens=args.max_tokens)\n",
    "    all_scores = run_eval(model, tokenizer, data, device)\n",
    "    data = pd.DataFrame(data)\n",
    "    data['scores'] = list(all_scores.to('cpu').numpy())\n",
    "    acc = np.sum(np.argmin(np.array(data['scores'].to_list()), axis=1) == 0) / len(data)\n",
    "    print(f\"acc = {acc}\")\n",
    "    data.to_json(get_results_path(args.output_folder, args.model_name), lines=True,\n",
    "                 orient='records')\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "def get_results_path(output_folder, model_name):\n",
    "    return os.path.join(output_folder, model_name.split('/')[-1] + '.jsonl')\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "\n",
    "#     # Data params\n",
    "#     parser.add_argument('--data_file', required=True, type=str, help=\"csv file\")\n",
    "#     parser.add_argument('--output_folder', required=True, type=str)\n",
    "\n",
    "#     # Model params\n",
    "#     parser.add_argument('--model_name', default='gpt2', type=str)\n",
    "#     parser.add_argument('--max_tokens', type=int, default=1024)\n",
    "\n",
    "#     parser.add_argument(\"--cache_dir\", type=str, default=\"/dev/shm/cache-transformers/\")\n",
    "#     args = parser.parse_args()\n",
    "#     main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'full_prefix': 'As streaming television services continue to gain market share, there are a number of reasons why Netflix might be in trouble. Time Warner is taking its HBO content online, Amazon offers premium content for a monthly fee, and Hulu has reached nine million users. While these competitors may cause a bit of worry, it’s not the end of the world. Although Netflix has a huge amount of potential, the increased competition is unlikely to hurt its profitability.\\nWhile the global pandemic last year caused a major shakeup in Hollywood, Netflix should not rest on its laurels. With a variety of rivals on the rise, it’s unlikely that it can continue to rely on its current performance. Despite the competition, the company has made a number of impactful moves across the board, including clamping down on password sharing. And in the coming years, Netflix should continue to grow and compete with new competitors.\\nWith more competitors entering the streaming space, Netflix is likely to face a more difficult time keeping its current market share. Disney has been investing heavily in the service and Amazon is expected to do the same. Both companies expect to add 35-40 million subscribers per year through 2024. Despite the competition, Netflix still remains the top streaming service. Its lack of original content has hurt its numbers in the last few quarters. Its only big original hit in the US was Cobra Kai, which only got four seasons. ', 'completion': 'Whether or not it gets a second season of The Witcher is another question.', 'contradictions': ['Whether or not it gets a second season of Stranger Things is another question.', 'Whether or not it gets a fifth season of The Witcher is another question.', 'Whether or not it gets a second season of Black Mirror is another question.']}\n",
      "acc = 0.13416988416988418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m acc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39margmin(np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m data\u001b[38;5;241m.\u001b[39mto_json(get_results_path(\u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39moutput_folder, args\u001b[38;5;241m.\u001b[39mmodel_name), lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m                 orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "prefix_col = 'turncated_prefixes'\n",
    "data = read_data('data/news_factor.csv', prefix_col)\n",
    "model, tokenizer, device = load_model_and_tokenizer('gpt2', './cache-transformers/', max_tokens=1024)\n",
    "all_scores = run_eval(model, tokenizer, data, device)\n",
    "data = pd.DataFrame(data)\n",
    "data['scores'] = list(all_scores.to('cpu').numpy())\n",
    "acc = np.sum(np.argmin(np.array(data['scores'].to_list()), axis=1) == 0) / len(data)\n",
    "print(f\"acc = {acc}\")\n",
    "data.to_json(get_results_path(args.output_folder, args.model_name), lines=True,\n",
    "                orient='records')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_prefix': 'As streaming television services continue to gain market share, there are a number of reasons why Netflix might be in trouble. Time Warner is taking its HBO content online, Amazon offers premium content for a monthly fee, and Hulu has reached nine million users. While these competitors may cause a bit of worry, it’s not the end of the world. Although Netflix has a huge amount of potential, the increased competition is unlikely to hurt its profitability.\\nWhile the global pandemic last year caused a major shakeup in Hollywood, Netflix should not rest on its laurels. With a variety of rivals on the rise, it’s unlikely that it can continue to rely on its current performance. Despite the competition, the company has made a number of impactful moves across the board, including clamping down on password sharing. And in the coming years, Netflix should continue to grow and compete with new competitors.\\nWith more competitors entering the streaming space, Netflix is likely to face a more difficult time keeping its current market share. Disney has been investing heavily in the service and Amazon is expected to do the same. Both companies expect to add 35-40 million subscribers per year through 2024. Despite the competition, Netflix still remains the top streaming service. Its lack of original content has hurt its numbers in the last few quarters. Its only big original hit in the US was Cobra Kai, which only got four seasons. ',\n",
       " 'completion': 'Whether or not it gets a second season of The Witcher is another question.',\n",
       " 'contradictions': ['Whether or not it gets a second season of Stranger Things is another question.',\n",
       "  'Whether or not it gets a fifth season of The Witcher is another question.',\n",
       "  'Whether or not it gets a second season of Black Mirror is another question.']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprep_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# format_data(data[0])\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 75\u001b[0m, in \u001b[0;36mprep_batch\u001b[0;34m(ex, tokenizer, device)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprep_batch\u001b[39m(ex, tokenizer, device):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# prepare examples for tokenization\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     batch, labels_batch \u001b[38;5;241m=\u001b[39m \u001b[43mformat_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# encode full text (context + completions)\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m tokenizer(batch, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[2], line 53\u001b[0m, in \u001b[0;36mformat_data\u001b[0;34m(ex)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat_data\u001b[39m(ex):\n\u001b[0;32m---> 53\u001b[0m     prefix \u001b[38;5;241m=\u001b[39m \u001b[43mex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull_prefix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     54\u001b[0m     completion \u001b[38;5;241m=\u001b[39m ex[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompletion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     55\u001b[0m     contradictions \u001b[38;5;241m=\u001b[39m ex[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontradictions\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# prep_batch(data[0], tokenizer, device)\n",
    "# format_data(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1101006"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"parquet\", data_files=\"/iopsstor/scratch/cscs/dfan/data/robots-txt/RawData-NYTimes/*.parquet\")\n",
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['train'].to_pandas().loc[:12800, 'text'].apply(lambda x: len(x.split())).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text\n",
       "(512.0, 1024.0]      392\n",
       "(256.0, 512.0]       244\n",
       "(1024.0, 2048.0]     156\n",
       "(128.0, 256.0]       141\n",
       "(2048.0, 4096.0]      43\n",
       "(-0.001, 128.0]       20\n",
       "(4096.0, 8192.0]       4\n",
       "(8192.0, 16384.0]      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = [0, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]\n",
    "pd.cut(dataset['train'].to_pandas().loc[:1000, 'text'].apply(lambda x: len(x.split())), bins=bins, include_lowest=True).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# get the first 20000 examples\n",
    "fset = dataset[\"train\"].select(range(12800))\n",
    "tokenizer = AutoTokenizer.from_pretrained('alehc/swissai-tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# # get the first 20000 examples\n",
    "# subset = dataset[\"train\"].select(range(12800))\n",
    "# tokenizer = AutoTokenizer.from_pretrained('alehc/swissai-tokenizer')\n",
    "\n",
    "def split_example(examples, input_size=128, max_tokens=4096):\n",
    "    # text = example['text']\n",
    "    # tokens = tokenizer.tokenize(text)\n",
    "    # input = tokenizer.convert_tokens_to_string(tokens[:input_size])\n",
    "    # target = tokenizer.convert_tokens_to_string(tokens[input_size:max_tokens])\n",
    "    # return {'input_text': input, 'target_text': target}\n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    \n",
    "    for i, text in enumerate(examples['text']):\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        input = tokenizer.convert_tokens_to_string(tokens[:input_size])\n",
    "        target = tokenizer.convert_tokens_to_string(tokens[input_size:max_tokens])\n",
    "        input_texts.append(input)\n",
    "        target_texts.append(target)\n",
    "    \n",
    "    return {'input_text': input_texts, 'target_text': target_texts}\n",
    "\n",
    "subset = fset.map(split_example, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_examples = subset.filter(lambda example: len(example['target_text']) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'id', 'metadata', 'input_text', 'target_text'],\n",
       "    num_rows: 12653\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 12653/12653 [00:00<00:00, 31417.12 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# # save the dataset\n",
    "# positive_examples.save_to_disk('/iopsstor/scratch/cscs/ansaripo/data/nytimes_verbatim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/bash: transform: command not found\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/ansaripo/miniconda3/envs/robots/bin/transformers-cli\", line 5, in <module>\n",
      "    from transformers.commands.transformers_cli import main\n",
      "  File \"/users/ansaripo/miniconda3/envs/robots/lib/python3.10/site-packages/transformers/commands/transformers_cli.py\", line 20, in <module>\n",
      "    from .chat import ChatCommand\n",
      "  File \"/users/ansaripo/miniconda3/envs/robots/lib/python3.10/site-packages/transformers/commands/chat.py\", line 29, in <module>\n",
      "    from rich.console import Console\n",
      "ModuleNotFoundError: No module named 'rich'\n"
     ]
    }
   ],
   "source": [
    "#login to huggingface\n",
    "!transform\n",
    "!transformers-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the dataset to the hub\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from huggingface_hub import login\n",
    "DatasetDict({'test': positive_examples}).push_to_hub('nytimes_verbatim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained('mistralai/Mistral-Nemo-Base-2407')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|██████████| 12653/12653 [00:00<00:00, 57455.53 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'id', 'metadata', 'input_text', 'target_text'],\n",
       "        num_rows: 12653\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset(\"mansaripo/nytimes_verbatim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|██████████| 4358/4358 [00:00<00:00, 389689.52 examples/s]\n",
      "Generating train split: 100%|██████████| 36718/36718 [00:00<00:00, 984481.98 examples/s]\n",
      "Generating validation split: 100%|██████████| 3760/3760 [00:00<00:00, 434678.84 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 36718\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "data_json = \"/iopsstor/scratch/cscs/ansaripo/deepseek_questions.json\"\n",
    "questions = json.load(open(data_json, \"r\"))\n",
    "\n",
    "qs = []\n",
    "for q in questions:\n",
    "    qs.append(q['generated_question'])\n",
    "\n",
    "# convert to hf dataset\n",
    "dataset = Dataset.from_list(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 455.01ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mansaripo/nytimes_completion/commit/3c76a1cfe47d093647fb4945618e307c9356d84e', commit_message='Upload dataset', commit_description='', oid='3c76a1cfe47d093647fb4945618e307c9356d84e', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/mansaripo/nytimes_completion', endpoint='https://huggingface.co', repo_type='dataset', repo_id='mansaripo/nytimes_completion'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetDict({'test': dataset}).push_to_hub('nytimes_completion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetDict({'test': Dataset.from_list([q['generated_question'] for q in questions])}).push_to_hub('nytimes_completion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
